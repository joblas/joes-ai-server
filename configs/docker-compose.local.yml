# ⚠️  DEPRECATED — Local installs are now native (no Docker)
#
# The local installer (install-local.sh / install-local.ps1) now installs
# Ollama and Open WebUI natively using Homebrew + pip (Mac/Linux) or
# winget + pip (Windows). Docker is NOT required for local installs.
#
# This file is kept only for reference or for users who prefer Docker.
# To use it: docker compose -f configs/docker-compose.local.yml up -d
#
# For the recommended native install, run:
#   Mac/Linux:  curl -fsSL https://raw.githubusercontent.com/joblas/joes-ai-server/main/install-local.sh | bash
#   Windows:    irm https://raw.githubusercontent.com/joblas/joes-ai-server/main/install-local.ps1 | iex

services:
  joes-ai-local:
    image: ghcr.io/open-webui/open-webui:ollama
    container_name: joes-ai-local
    restart: unless-stopped
    ports:
      - "3000:8080"
    volumes:
      - joes-ai-ollama:/root/.ollama
      - joes-ai-webui:/app/backend/data

volumes:
  joes-ai-ollama:
  joes-ai-webui:

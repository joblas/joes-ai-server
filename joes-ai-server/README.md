# ğŸ›¡ï¸ Joe's AI Server

**Private, Self-Hosted AI Chat â€” Deployed in Minutes**

By [Joe's Tech Solutions LLC](https://joestechsolutions.com)

---

## What This Is

A turnkey deployment toolkit for installing a private AI chat server (Ollama + Open WebUI) on either a local computer or a cloud VPS. One command. Full privacy. No API fees.

### Two Products, One Repo

| Product | Target | What They Get |
|---|---|---|
| **Joe's Local AI** | Individuals, home offices | Private ChatGPT alternative on their own computer |
| **Joe's Cloud AI** | Small businesses, teams | Hosted AI server with HTTPS, custom domain, auto-updates |

---

## Quick Start

### ğŸ–¥ï¸ Local Install

**Prerequisites:** [Docker Desktop](https://docs.docker.com/get-docker/) installed and running.

**Mac / Linux:**
```bash
curl -fsSL https://raw.githubusercontent.com/joblas/joes-ai-server/main/install-local.sh | bash
```

**Windows (PowerShell as Administrator):**
```powershell
irm https://raw.githubusercontent.com/joblas/joes-ai-server/main/install-local.ps1 | iex
```

Then open **http://localhost:3000** and create your admin account.

### â˜ï¸ VPS Install (Hostinger / Any Ubuntu VPS)

**Prerequisites:** Fresh Ubuntu 22.04+ VPS with a domain pointed at it.

```bash
AI_DOMAIN=ai.yourclient.com \
EMAIL=admin@yourclient.com \
curl -fsSL https://raw.githubusercontent.com/joblas/joes-ai-server/main/install-vps.sh | bash
```

Then visit **https://ai.yourclient.com** once DNS propagates.

---

## What's Included

### Core Stack
- **[Ollama](https://ollama.com)** â€” Run LLMs locally (Llama 3.2, Mistral, Phi-3, DeepSeek, etc.)
- **[Open WebUI](https://docs.openwebui.com)** â€” Beautiful ChatGPT-style interface with RAG, multi-user, model management

### VPS Extras
- **[Caddy](https://caddyserver.com)** â€” Automatic HTTPS with Let's Encrypt
- **[Watchtower](https://github.com/nickfedor/watchtower)** â€” Auto-updates all containers (monitor-only mode by default)
- **Health check endpoint** â€” Simple uptime monitoring
- **Automated backups** â€” Daily volume snapshots with 7-day retention

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Client Browser                  â”‚
â”‚         https://ai.client.com                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Caddy (443/80)                  â”‚
â”‚         Auto HTTPS + Reverse Proxy           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Open WebUI (:8080)                 â”‚
â”‚    Chat UI Â· RAG Â· User Management           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Ollama (:11434)                   â”‚
â”‚     LLM Inference Â· Model Management         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                          â–²
    Watchtower                 Health Check
   (auto-updates)            (uptime monitor)
```

---

## Hardware Requirements

| Tier | RAM | Storage | Good For |
|---|---|---|---|
| Minimum | 8 GB | 20 GB | Small models (Phi-3, Gemma 2B) |
| Recommended | 16 GB | 50 GB | Medium models (Llama 3.2 8B, Mistral 7B) |
| Power User | 32 GB+ | 100 GB+ | Large models (Llama 3.1 70B quantized) |

For VPS: Hostinger KVM 2 (8 GB RAM, $12/mo) is the sweet spot for small business use.

---

## Management Commands

```bash
# Check status
cd /opt/joes-ai-stack && docker compose ps

# View logs
docker compose logs -f open-webui

# Update everything
docker compose pull && docker compose up -d

# Pull a new model
docker exec ollama ollama pull llama3.2

# List downloaded models
docker exec ollama ollama list

# Restart stack
docker compose restart

# Full backup (VPS)
/opt/joes-ai-stack/scripts/backup.sh
```

---

## File Structure

```
joes-ai-server/
â”œâ”€â”€ install-local.sh          # One-liner for Mac / Linux
â”œâ”€â”€ install-local.ps1         # One-liner for Windows (PowerShell)
â”œâ”€â”€ install-vps.sh            # One-liner for VPS deployment
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ docker-compose.yml    # Full stack (Ollama + WebUI + Caddy + Watchtower)
â”‚   â”œâ”€â”€ docker-compose.local.yml  # Simplified local-only stack
â”‚   â”œâ”€â”€ Caddyfile.template    # HTTPS reverse proxy config
â”‚   â””â”€â”€ .env.example          # Environment variable template
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ backup.sh             # Automated backup script
â”‚   â”œâ”€â”€ restore.sh            # Restore from backup
â”‚   â”œâ”€â”€ health-check.sh       # Uptime monitoring endpoint
â”‚   â””â”€â”€ update.sh             # Manual update trigger
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CLIENT_GUIDE.md       # End-user documentation
â”‚   â”œâ”€â”€ PRICING.md            # Service pricing reference
â”‚   â””â”€â”€ TROUBLESHOOTING.md    # Common issues and fixes
â””â”€â”€ README.md
```

---

## Support

This is a service product of **Joe's Tech Solutions LLC**.

- ğŸ“§ Email: joe@joestechsolutions.com
- ğŸŒ Website: https://joestechsolutions.com

---

## License

Scripts and configurations are MIT licensed. Ollama, Open WebUI, Caddy, and Watchtower each have their own licenses.
